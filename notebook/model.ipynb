{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルファイル\n",
    "最終的にはpyファイルにして、引数でデータのバージョン管理ができるようにすること"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T23:39:40.784373Z",
     "start_time": "2019-03-21T23:39:40.389577Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, pdb\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import gc\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "DATA_DIR = Path('../input')\n",
    "MODEL_DIR = Path('../model')\n",
    "OUT_DIR = Path('../output')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-21T23:39:49.723557Z",
     "start_time": "2019-03-21T23:39:49.483166Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "from random import shuffle\n",
    "import random\n",
    "random.seed(seed)\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models, transforms, utils\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T09:37:29.669082Z",
     "start_time": "2019-03-22T09:37:29.662482Z"
    }
   },
   "outputs": [],
   "source": [
    "supported_rnns = {\n",
    "    'lstm': nn.LSTM,\n",
    "    'rnn': nn.RNN,\n",
    "    'gru': nn.GRU\n",
    "}\n",
    "supported_rnns_inv = dict((v, k) for k, v in supported_rnns.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T09:50:18.922224Z",
     "start_time": "2019-03-22T09:50:18.919167Z"
    }
   },
   "outputs": [],
   "source": [
    "from eeglibrary import EEG, EEGDataSet, EEGDataLoader, EEGParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-22T11:53:18.533259Z",
     "start_time": "2019-03-22T11:53:18.524591Z"
    }
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.lr = 3e-4\n",
    "        self.epochs = 50\n",
    "        self.continue_from = False\n",
    "        self.momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    part: EEGDataSet(data_dir / 'manifests' / '{}_{}_manifest.csv'.format(data_version, part), eeg_conf)\n",
    "    for part in partial_name_list\n",
    "}\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "dataloaders = {part: EEGDataLoader(datasets[part], batch_size=2, num_workers=2) \n",
    "               for part in partial_name_list}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "# if __name__ == '__main__':\n",
    "# parse args\n",
    "args = Args()\n",
    "# set seeds: torch, cuda, np, random\n",
    "# device setting\n",
    "# make best model save dir\n",
    "model_dir = model_dir\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "roc_results, prec_results, rec_results = torch.Tensor(args.epochs), torch.Tensor(args.epochs), torch.Tensor(\n",
    "    args.epochs)\n",
    "\n",
    "best_roc = None\n",
    "\n",
    "avg_loss, avg_auc, start_epoch, start_iter, optim_state = 0, 0, 0, 0, None\n",
    "\n",
    "if args.continue_from:  # TODO: Starting from previous model\n",
    "    raise NotImplementedError\n",
    "    \n",
    "model = models.vgg11_bn(pretrained=True)\n",
    "num_ftrs = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_ftrs, len(class_names))\n",
    "input_size = 224\n",
    "model = model.to(device)\n",
    "\n",
    "parameters = model.parameters()\n",
    "optimizer = torch.optim.SGD(parameters, lr=args.lr,\n",
    "                            momentum=args.momentum, nesterov=True, weight_decay=1e-5)\n",
    "\n",
    "# if optim_state is not None:\n",
    "#     optimizer.load_state_dict(optim_state)\n",
    "\n",
    "# print(model)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "batch_time = AverageMeter()\n",
    "data_time = AverageMeter()\n",
    "losses = AverageMeter()\n",
    "\n",
    "for epoch in range(start_epoch, args.epochs):\n",
    "    end = time.time()\n",
    "    start_epoch_time = time.time()\n",
    "    \n",
    "    for phase in ['train', 'val']:\n",
    "#         if phase == 'train':\n",
    "#             scheduler.step()\n",
    "        \n",
    "        for i, inputs, labels in enumerate(dataloaders[phase]):\n",
    "            # measure data loading time\n",
    "            data_time.update(time.time() - end)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                pdb.set_trace()\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "            avg_loss += loss.item()\n",
    "            avg_auc += metrics.auc(labels, outputs)\n",
    "            losses.update(loss_value, inputs.size(0))\n",
    "            \n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            if True: #not args.silent:\n",
    "                print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                    (epoch + 1), (i + 1), len(train_sampler), batch_time=batch_time, data_time=data_time, loss=losses))\n",
    "            break\n",
    "        # deep copy the model\n",
    "        if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
